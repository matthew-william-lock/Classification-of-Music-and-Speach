{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import scipy.fftpack\n",
    "import math\n",
    "import soundfile as sf\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Required to train and split the data\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Required to import the data\n",
    "from os import listdir\n",
    "\n",
    "# KNN Imports\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "# Kfold \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of onset_strength_peak_rate : 1000\nLength of flux : 1000\nLength of var_zc : 1000\nLength of low_energy_frame_percentages : 1000\nLength of all_labels : 1000\n"
    }
   ],
   "source": [
    "onset_strength_peak_rate = np.loadtxt('extracted_features/onset_strength_peak_rate_1000.csv', delimiter=',',dtype=np.double)\n",
    "flux = np.loadtxt('extracted_features/norm_2_1000.csv', delimiter=',',dtype=np.double)\n",
    "var_zc = np.loadtxt('extracted_features/var_zc_1000.csv', delimiter=',',dtype=np.double)\n",
    "low_energy_frame_percentages =  np.loadtxt('extracted_features/low_energy_frame_percentages_1000.csv', delimiter=',',dtype=np.double)\n",
    "all_labels = np.loadtxt('extracted_features/labels_zc1_1000.csv', delimiter=',')\n",
    "\n",
    "print(\"Length of onset_strength_peak_rate : {}\".format(len(onset_strength_peak_rate)))\n",
    "print(\"Length of flux : {}\".format(len(flux)))\n",
    "print(\"Length of var_zc : {}\".format(len(var_zc)))\n",
    "print(\"Length of low_energy_frame_percentages : {}\".format(len(low_energy_frame_percentages)))\n",
    "print(\"Length of all_labels : {}\".format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers, Normalize, and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(x, outlierConstant):\n",
    "    a = np.array(x)\n",
    "    # print(a.shape)\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    \n",
    "    result = []\n",
    "    removed = []\n",
    "    \n",
    "    for i,value in enumerate(a):\n",
    "        if ((value >= quartileSet[0]) and (value <= quartileSet[1])): result.append(value)\n",
    "        else: removed.append(i)\n",
    "    \n",
    "    return np.array(removed), np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of onset_strength_peak_rate : 962\nLength of var_zc : 962\nLength of low_energy_frame_percentages : 962\nLength of all_labels : 962\n"
    }
   ],
   "source": [
    "# Remove outliers caused by var_vc\n",
    "removed, var_zc = removeOutliers(var_zc,1.5)\n",
    "onset_strength_peak_rate = np.delete(onset_strength_peak_rate,removed)\n",
    "low_energy_frame_percentages = np.delete(low_energy_frame_percentages,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Remove outliers caused by onset_strength_peak_rate\n",
    "removed, onset_strength_peak_rate = removeOutliers(onset_strength_peak_rate,1.5)\n",
    "var_zc = np.delete(var_zc,removed)\n",
    "low_energy_frame_percentages = np.delete(low_energy_frame_percentages,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Remove outliers caused by low_energy_frame_percentages\n",
    "removed, low_energy_frame_percentages = removeOutliers(low_energy_frame_percentages,1.5)\n",
    "var_zc = np.delete(var_zc,removed)\n",
    "onset_strength_peak_rate = np.delete(onset_strength_peak_rate,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Normalise the Data\n",
    "flux = flux / flux.max()\n",
    "var_zc = var_zc / var_zc.max()\n",
    "onset_strength_peak_rate = onset_strength_peak_rate / onset_strength_peak_rate.max()\n",
    "low_energy_frame_percentages = low_energy_frame_percentages / low_energy_frame_percentages.max()\n",
    "\n",
    "print(\"Length of onset_strength_peak_rate : {}\".format(len(onset_strength_peak_rate)))\n",
    "print(\"Length of var_zc : {}\".format(len(var_zc)))\n",
    "print(\"Length of low_energy_frame_percentages : {}\".format(len(low_energy_frame_percentages)))\n",
    "print(\"Length of all_labels : {}\".format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn for Flux Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 1000\nAverage Accuracy Score : 90.70 %\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [flux[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    X_test = X_test / X_test.max()\n",
    "\n",
    "    clf.fit(X_train,all_labels[train_indices])\n",
    "    z = clf.predict(X_test)\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.2f} %\".format(sum/splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For ZCR Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 1000\nAverage Accuracy Score : 75.50 %\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [var_zc[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    X_test = X_test / X_test.max()\n",
    "\n",
    "    clf.fit(X_train,all_labels[train_indices])\n",
    "    z = clf.predict(X_test)\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.2f} %\".format(sum/splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For Low Energy Frames Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 1000\nAverage Accuracy Score : 63.30 %\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [low_energy_frame_percentages[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    # X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    # X_test = X_test / X_test.max()\n",
    "\n",
    "    clf.fit(X_train,all_labels[train_indices])\n",
    "    z = clf.predict(X_test)\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.2f} %\".format(sum/splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average Accuracy Score : 96.30 %\n"
    }
   ],
   "source": [
    "X = np.array([ [flux[i],var_zc[i],low_energy_frame_percentages[i]] for i,x in enumerate(var_zc) ])\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Get Data\n",
    "    X_train_flux = flux[train_indices]\n",
    "    X_train_low_e = low_energy_frame_percentages[train_indices]\n",
    "    X_train_var_zc = var_zc[train_indices]\n",
    "\n",
    "    X_test_flux = flux[test_indices]\n",
    "    X_test_low_e = low_energy_frame_percentages[test_indices]\n",
    "    X_test_var_zc = var_zc[test_indices]\n",
    "\n",
    "    # normalise data\n",
    "    X_train_flux = X_train_flux / X_train_flux.max()\n",
    "    X_train_low_e = X_train_low_e / X_train_low_e.max()\n",
    "    X_train_var_zc = X_train_var_zc / X_train_var_zc.max()\n",
    "\n",
    "    X_test_flux = X_test_flux / X_test_flux.max()\n",
    "    X_test_low_e = X_test_low_e / X_test_low_e.max()\n",
    "    X_test_var_zc = X_test_var_zc / X_test_var_zc.max()\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = np.array([ [X_train_flux[i],X_train_var_zc[i],X_train_low_e[i]] for i,x in enumerate(train_indices) ])\n",
    "    # X_train = X_train / X_train.max() \n",
    "    X_test = np.array([ [X_test_flux[i],X_test_var_zc[i],X_test_low_e[i]] for i,x in enumerate(test_indices) ])\n",
    "    # X_test = X_test / X_test.max()\n",
    "\n",
    "    clf.fit(X_train,all_labels[train_indices])\n",
    "    z = clf.predict(X_test)\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.2f} %\".format(sum/splits))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit4ee73244bb464323ae53617443151c45",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}