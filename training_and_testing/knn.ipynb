{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import scipy.fftpack\n",
    "import math\n",
    "import soundfile as sf\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Required to train and split the data\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Required to import the data\n",
    "from os import listdir\n",
    "\n",
    "# KNN Imports\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "# Kfold \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Time keeping\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Speech files : 4000\nNumber of Music files : 4000\nNumber of total files : 8000\n"
    }
   ],
   "source": [
    "speech_files = np.loadtxt('extracted_features/speech_files.csv', delimiter=',',dtype=str)\n",
    "music_files = np.loadtxt('extracted_features/music_files.csv', delimiter=',',dtype=str)\n",
    "\n",
    "speech_files=speech_files[0:4000]\n",
    "music_files=music_files[0:4000]\n",
    "\n",
    "all_files = np.append(speech_files,music_files)\n",
    "\n",
    "print(\"Number of Speech files : {}\".format(len(speech_files)))\n",
    "print(\"Number of Music files : {}\".format(len(music_files)))\n",
    "print(\"Number of total files : {}\".format(len(all_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of flux : 8000\nLength of var_zc : 8000\nLength of low_energy_frame_percentages : 8000\nLength of mfccs : 8000\nLength of all_labels : 8000\n"
    }
   ],
   "source": [
    "# onset_strength_peak_rate = np.loadtxt('extracted_features/onset_strength_peak_rate_8000.csv', delimiter=',',dtype=np.double)\n",
    "flux = np.loadtxt('extracted_features/norm_2_8000.csv', delimiter=',',dtype=np.double)\n",
    "var_zc = np.loadtxt('extracted_features/var_zc_8000.csv', delimiter=',',dtype=np.double)\n",
    "low_energy_frame_percentages =  np.loadtxt('extracted_features/low_energy_frame_percentages_8000.csv', delimiter=',',dtype=np.double)\n",
    "mfccs = np.loadtxt('extracted_features/mfccs_8000.csv', delimiter=',',dtype=np.double)\n",
    "all_labels = np.loadtxt('extracted_features/labels_zc_8000.csv', delimiter=',')\n",
    "\n",
    "# print(\"Length of onset_strength_peak_rate : {}\".format(len(onset_strength_peak_rate)))\n",
    "print(\"Length of flux : {}\".format(len(flux)))\n",
    "print(\"Length of var_zc : {}\".format(len(var_zc)))\n",
    "print(\"Length of low_energy_frame_percentages : {}\".format(len(low_energy_frame_percentages)))\n",
    "print(\"Length of mfccs : {}\".format(len(mfccs)))\n",
    "print(\"Length of all_labels : {}\".format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers, Normalize, and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(x, outlierConstant):\n",
    "    a = np.array(x)\n",
    "    # print(a.shape)\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    \n",
    "    result = []\n",
    "    removed = []\n",
    "    \n",
    "    for i,value in enumerate(a):\n",
    "        if ((value >= quartileSet[0]) and (value <= quartileSet[1])): result.append(value)\n",
    "        else: removed.append(i)\n",
    "    \n",
    "    return np.array(removed), np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of onset_strength_peak_rate : 962\nLength of var_zc : 962\nLength of low_energy_frame_percentages : 962\nLength of all_labels : 962\n"
    }
   ],
   "source": [
    "# Remove outliers caused by var_vc\n",
    "removed, var_zc = removeOutliers(var_zc,1.5)\n",
    "onset_strength_peak_rate = np.delete(onset_strength_peak_rate,removed)\n",
    "low_energy_frame_percentages = np.delete(low_energy_frame_percentages,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Remove outliers caused by onset_strength_peak_rate\n",
    "removed, onset_strength_peak_rate = removeOutliers(onset_strength_peak_rate,1.5)\n",
    "var_zc = np.delete(var_zc,removed)\n",
    "low_energy_frame_percentages = np.delete(low_energy_frame_percentages,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Remove outliers caused by low_energy_frame_percentages\n",
    "removed, low_energy_frame_percentages = removeOutliers(low_energy_frame_percentages,1.5)\n",
    "var_zc = np.delete(var_zc,removed)\n",
    "onset_strength_peak_rate = np.delete(onset_strength_peak_rate,removed)\n",
    "all_labels = np.delete(all_labels,removed)\n",
    "\n",
    "# Normalise the Data\n",
    "flux = flux / flux.max()\n",
    "var_zc = var_zc / var_zc.max()\n",
    "onset_strength_peak_rate = onset_strength_peak_rate / onset_strength_peak_rate.max()\n",
    "low_energy_frame_percentages = low_energy_frame_percentages / low_energy_frame_percentages.max()\n",
    "\n",
    "print(\"Length of onset_strength_peak_rate : {}\".format(len(onset_strength_peak_rate)))\n",
    "print(\"Length of var_zc : {}\".format(len(var_zc)))\n",
    "print(\"Length of low_energy_frame_percentages : {}\".format(len(low_energy_frame_percentages)))\n",
    "print(\"Length of all_labels : {}\".format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn for Flux Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 8000\nAverage Accuracy Score : 92.237 ± 0.437 %\nAverage Training Time : 3.0 ± 0.001 ms\nAverage Single Prediction Time : 0.00212 ± 0.000 ms\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [flux[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "# Track Results\n",
    "result_list=[]\n",
    "\n",
    "# Track Timing\n",
    "training_times=[]\n",
    "predicting_time=[]\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    X_test = X_test / X_test.max()\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    clf.fit(X_train,all_labels[train_indices])  # Train the model\n",
    "    training_times.append(time.time()-start_time)\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    z = clf.predict(X_test)                     # Perform predictions\n",
    "    predicting_time.append( (time.time()-start_time)/z.size )\n",
    "\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    result_list.append(correct_pred/len(test_indices)*100)\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(result_list)/splits,np.var(result_list)))\n",
    "print(\"Average Training Time : {:3.3} ± {:3.3f} ms\".format(np.sum(training_times)/splits*1000,np.var(training_times)*1000))\n",
    "print(\"Average Single Prediction Time : {:3.3} ± {:3.3f} ms\".format(np.sum(predicting_time)/splits*1000,np.var(predicting_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For ZCR Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 8000\nAverage Accuracy Score : 76.412 ± 1.988 %\nAverage Training Time : 3.79 ± 0.000 ms\nAverage Single Prediction Time : 0.00237 ± 0.000 ms\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [var_zc[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "\n",
    "# Track Results\n",
    "result_list=[]\n",
    "\n",
    "# Track Timing\n",
    "training_times=[]\n",
    "predicting_time=[]\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    X_test = X_test / X_test.max()\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    clf.fit(X_train,all_labels[train_indices])  # Train the model\n",
    "    training_times.append(time.time()-start_time)\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    z = clf.predict(X_test)                     # Perform predictions\n",
    "    predicting_time.append( (time.time()-start_time)/z.size )\n",
    "\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    result_list.append(correct_pred/len(test_indices)*100)\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(result_list)/splits,np.var(result_list)))\n",
    "print(\"Average Training Time : {:3.3} ± {:3.3f} ms\".format(np.sum(training_times)/splits*1000,np.var(training_times)*1000))\n",
    "print(\"Average Single Prediction Time : {:3.3} ± {:3.3f} ms\".format(np.sum(predicting_time)/splits*1000,np.var(predicting_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For Low Energy Frames Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 8000\nAverage Accuracy Score : 89.475 ± 2.240 %\nAverage Training Time : 3.2 ± 0.000 ms\nAverage Single Prediction Time : 0.00224 ± 0.000 ms\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ [low_energy_frame_percentages[i]] for i,x in enumerate(var_zc) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 5\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "# Track Results\n",
    "result_list=[]\n",
    "\n",
    "# Track Timing\n",
    "training_times=[]\n",
    "predicting_time=[]\n",
    "\n",
    "\n",
    "sum = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    X_test = X_test / X_test.max()\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    clf.fit(X_train,all_labels[train_indices])  # Train the model\n",
    "    training_times.append(time.time()-start_time)\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    z = clf.predict(X_test)                     # Perform predictions\n",
    "    predicting_time.append( (time.time()-start_time)/z.size )\n",
    "\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    result_list.append(correct_pred/len(test_indices)*100)\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(result_list)/splits,np.var(result_list)))\n",
    "print(\"Average Training Time : {:3.3} ± {:3.3f} ms\".format(np.sum(training_times)/splits*1000,np.var(training_times)*1000))\n",
    "print(\"Average Single Prediction Time : {:3.3} ± {:3.3f} ms\".format(np.sum(predicting_time)/splits*1000,np.var(predicting_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN For All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4000\nAverage Speech Accuracy Score : 98.850 ± 1.137 %\nAverage Music Accuracy Score : 95.775 ± 4.046 %\nAverage Accuracy Score : 97.312 ± 0.276 %\nAverage Training Time : 4.69 ± 0.000 ms\nAverage Single Prediction Time : 0.0086 ± 0.000 ms\n"
    }
   ],
   "source": [
    "X = np.array([ [flux[i],var_zc[i],low_energy_frame_percentages[i]] for i,x in enumerate(var_zc) ])\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 25\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    "\n",
    "# Track Results\n",
    "result_list=[]\n",
    "speech_results=[]\n",
    "music_results=[]\n",
    "\n",
    "# Track Timing\n",
    "training_times=[]\n",
    "predicting_time=[]\n",
    "\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Get Data\n",
    "    X_train_flux = flux[train_indices]\n",
    "    X_train_low_e = low_energy_frame_percentages[train_indices]\n",
    "    X_train_var_zc = var_zc[train_indices]\n",
    "\n",
    "    X_test_flux = flux[test_indices]\n",
    "    X_test_low_e = low_energy_frame_percentages[test_indices]\n",
    "    X_test_var_zc = var_zc[test_indices]\n",
    "\n",
    "    # normalise data\n",
    "    X_train_flux = X_train_flux / X_train_flux.max()\n",
    "    X_train_low_e = X_train_low_e / X_train_low_e.max()\n",
    "    X_train_var_zc = X_train_var_zc / X_train_var_zc.max()\n",
    "\n",
    "    X_test_flux = X_test_flux / X_test_flux.max()\n",
    "    X_test_low_e = X_test_low_e / X_test_low_e.max()\n",
    "    X_test_var_zc = X_test_var_zc / X_test_var_zc.max()\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = np.array([ [X_train_flux[i],X_train_var_zc[i],X_train_low_e[i]] for i,x in enumerate(train_indices) ])\n",
    "    # X_train = X_train / X_train.max() \n",
    "    X_test = np.array([ [X_test_flux[i],X_test_var_zc[i],X_test_low_e[i]] for i,x in enumerate(test_indices) ])\n",
    "    # X_test = X_test / X_test.max()\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    clf.fit(X_train,all_labels[train_indices])  # Train the model\n",
    "    training_times.append(time.time()-start_time)\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    z = clf.predict(X_test)                     # Perform predictions\n",
    "    predicting_time.append( (time.time()-start_time)/z.size )    \n",
    "    \n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        # Track overall accuracy\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "        # Track predictions of speech\n",
    "        if all_labels[test_indices][x] == 0 : \n",
    "            if value == all_labels[test_indices][x]: speech_results.append(1)\n",
    "            else : speech_results.append(0)\n",
    "        # Track predictions of music\n",
    "        if all_labels[test_indices][x] == 1 : \n",
    "            if value == all_labels[test_indices][x]: music_results.append(1)\n",
    "            else : music_results.append(0)\n",
    "\n",
    "    result_list.append(correct_pred/len(test_indices)*100)\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Speech Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(speech_results)/len(speech_results)*100,np.var(speech_results)*100))\n",
    "print(\"Average Music Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(music_results)/len(music_results)*100,np.var(music_results)*100))\n",
    "print(\"Average Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(result_list)/splits,np.var(result_list)))\n",
    "print(\"Average Training Time : {:3.3} ± {:3.3f} ms\".format(np.sum(training_times)/splits*1000,np.var(training_times)*1000))\n",
    "print(\"Average Single Prediction Time : {:3.3} ± {:3.3f} ms\".format(np.sum(predicting_time)/splits*1000,np.var(predicting_time)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of combined data : 8000\nAverage Speech Accuracy Score : 99.775 ± 0.224 %\nAverage Music Accuracy Score : 92.575 ± 6.874 %\nAverage Accuracy Score : 96.175 ± 0.201 %\nAverage Training Time : 92.9 ± 0.012 ms\nAverage Single Prediction Time : 0.209 ± 0.000 ms\n"
    }
   ],
   "source": [
    "# Get data\n",
    "X = np.array([ mfccs[i] for i,x in enumerate(mfccs) ])\n",
    "print(\"Length of combined data : {}\".format(len(X)))\n",
    "\n",
    "# Knn\n",
    "n_neighbors  = 25\n",
    "weights = 'distance'\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights=weights,algorithm='kd_tree')\n",
    "\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits,shuffle=True)\n",
    "\n",
    "sum = 0\n",
    " \n",
    "# Track Results\n",
    "result_list=[]\n",
    "speech_results=[]\n",
    "music_results=[]\n",
    "\n",
    "# Track Timing\n",
    "training_times=[]\n",
    "predicting_time=[]\n",
    "\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # Normalise the Data independently\n",
    "    X_train = X[train_indices] \n",
    "    # X_train = X_train / X_train.max() \n",
    "    X_test = X[test_indices] \n",
    "    # X_test = X_test / X_test.max()\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    clf.fit(X_train,all_labels[train_indices])  # Train the model\n",
    "    training_times.append(time.time()-start_time)\n",
    "\n",
    "    start_time = time.time()                    # Keep Time\n",
    "    z = clf.predict(X_test)                     # Perform predictions\n",
    "    predicting_time.append( (time.time()-start_time)/z.size )\n",
    "\n",
    "\n",
    "    correct_pred = 0\n",
    "    for x,value in enumerate(z):\n",
    "        # Track overall accuracy\n",
    "        if value == all_labels[test_indices][x]: correct_pred+=1\n",
    "        # Track predictions of speech\n",
    "        if all_labels[test_indices][x] == 0 : \n",
    "            if value == all_labels[test_indices][x]: speech_results.append(1)\n",
    "            else : \n",
    "                speech_results.append(0)\n",
    "                # print(all_files[test_indices][x])\n",
    "        # Track predictions of music\n",
    "        if all_labels[test_indices][x] == 1 : \n",
    "            if value == all_labels[test_indices][x]: music_results.append(1)\n",
    "            else : \n",
    "                music_results.append(0)\n",
    "                # print(all_files[test_indices][x])\n",
    "\n",
    "    sum += correct_pred/len(test_indices)*100\n",
    "    result_list.append(correct_pred/len(test_indices)*100)\n",
    "    # print(correct_pred/len(test_indices)*100)\n",
    "\n",
    "print(\"Average Speech Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(speech_results)/len(speech_results)*100,np.var(speech_results)*100))\n",
    "print(\"Average Music Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(music_results)/len(music_results)*100,np.var(music_results)*100))\n",
    "print(\"Average Accuracy Score : {:3.3f} ± {:3.3f} %\".format(np.sum(result_list)/splits,np.var(result_list)))\n",
    "print(\"Average Training Time : {:3.3} ± {:3.3f} ms\".format(np.sum(training_times)/splits*1000,np.var(training_times)*1000))\n",
    "print(\"Average Single Prediction Time : {:3.3} ± {:3.3f} ms\".format(np.sum(predicting_time)/splits*1000,np.var(predicting_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit4ee73244bb464323ae53617443151c45",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}